import os
from main.Crawldata import *  
from main.Process import *
from streamlit_option_menu import option_menu
import streamlit as st
from pathlib import Path
import time
import base64
import pandas as pd
import plotly.express as px
import torch
import transformers
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import itertools
import collections
from nltk import bigrams


st.set_page_config(page_title='Twan-final', layout="wide", initial_sidebar_state="expanded", page_icon="üçµ")

@st.cache_data
def get_img_as_base64(file):
    with open(file, "rb") as f:
        return base64.b64encode(f.read()).decode()

# ƒê∆∞·ªùng d·∫´n h√¨nh ·∫£nh
img_path = Path(__file__).parent / "Webapp_files/image.jpg"
img = get_img_as_base64(img_path)

# ƒê∆∞·ªùng d·∫´n chromedriver
chrome_driver_path = Path(__file__).parent / "chromedriver.exe"

# Thi·∫øt l·∫≠p background cho trang
page_bg_img = f"""
<style>
[data-testid="stAppViewContainer"] > .main {{
background-image: url("https://images.unsplash.com/photo-1681735342773-d452708e87e7");
background-size: 175%;
background-position: top middel;
background-repeat: no-repeat;
background-attachment: local;
}}
[data-testid="stSidebar"] > div:first-child {{
background-image: url("data:image/png;base64,{img}");
background-position: center; 
background-repeat: no-repeat;
background-attachment: fixed;
}}
[data-testid="stHeader"] {{
background: rgba(0,0,0,0);
}}
[data-testid="stToolbar"] {{
right: 2rem;
}}
</style>
"""

def save_to_csv(df, file_path=Path(__file__).parent / 'Webapp_files/Reviews_crawled.csv'):
    if os.path.isfile(file_path):
        existing_df = pd.read_csv(file_path)
        combined_df = pd.concat([existing_df, df], ignore_index=True).drop_duplicates()
    else:
        combined_df = df.drop_duplicates()

    combined_df.to_csv(file_path, index=False)
    st.success(f"ƒê√£ l∆∞u {len(combined_df)} ƒë√°nh gi√° v√†o {file_path}")

@st.cache_resource
def load_sentiment_model():
    tokenizer = AutoTokenizer.from_pretrained('mr4/phobert-base-vi-sentiment-analysis')
    model = AutoModelForSequenceClassification.from_pretrained("TwanNDT/phobert-fpt_telecomreview")
    return tokenizer, model

tokenizer_sentiment, model_sentiment = load_sentiment_model()

def main():
    st.markdown(page_bg_img, unsafe_allow_html=True)

    # Kh·ªüi t·∫°o fig v√† plt v·ªõi gi√° tr·ªã None trong session state
    if 'fig' not in st.session_state:
        st.session_state.fig = None
    if 'plt' not in st.session_state:
        st.session_state.plt = plt  # Kh·ªüi t·∫°o plt trong session_state
    if 'final_df' not in st.session_state:
        st.session_state.final_df = pd.DataFrame()
    if 'sentiment_counts' not in st.session_state:
        st.session_state.sentiment_counts = None

    with st.sidebar:
        selected = option_menu(
            menu_title="Menu",
            options=["Menu", "Ph√¢n t√≠ch ƒë√°nh gi√°"],
            icons=["house", "database"],
            menu_icon="cpu_fill",
            default_index=0,
        )

    if selected == "Menu":
        st.title("Gi·ªõi thi·ªáu")
        st.write("Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi ·ª©ng d·ª•ng ph√¢n t√≠ch ƒë√°nh gi√° c·ªßa kh√°ch h√†ng v·ªÅ FPT Telecom!")

    elif selected == "Ph√¢n t√≠ch ƒë√°nh gi√°":
        st.title("**Thu th·∫≠p v√† ph√¢n t√≠ch ƒë√°nh gi√°**")

        if not st.session_state.final_df.empty:           
            with st.container():
                st.header("B·∫£ng Comment thu th·∫≠p ƒë∆∞·ª£c:")
            # st.write('**B·∫£ng Comment thu th·∫≠p ƒë∆∞·ª£c:**')
            st.dataframe(st.session_state.final_df, use_container_width=True)

            # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì n·∫øu c√≥
            if st.session_state.sentiment_counts is not None and st.session_state.fig is not None:
                st.header("Bi·ªÉu ƒë·ªì ph√¢n t√≠ch c·∫£m x√∫c")
                st.plotly_chart(st.session_state.fig)
                st.header("Word Cloud t·ª´ c√°c ƒë√°nh gi√°")
                st.pyplot(st.session_state.plt)
                st.header("Trung b√¨nh Rating theo nƒÉm")
                st.plotly_chart(st.session_state.fig_rating)

        url_input = st.text_input("Nh·∫≠p v√†o URL c·ªßa chi nh√°nh c·∫ßn ƒë√°nh gi√° (ngƒÉn c√°ch b·ªüi 'and'):") 

        if st.button("L·∫•y ƒë√°nh gi√°"):
            if url_input: 
                urls = [url.strip() for url in url_input.split('and')]
                driver_path = Path(__file__).parent / "chromedriver.exe"
                service = Service(executable_path=str(driver_path))
                chrome_options = Options()
                chrome_options.add_argument("--headless")
                chrome_options.add_argument("--log-level=3")
                chrome_options.add_argument("--start-maximized")
                chrome_options.add_argument("--disable-gpu")
                chrome_options.add_argument("--no-sandbox")
                chrome_options.add_argument("--disable-dev-shm-usage")
                chrome_options.add_argument('--disable-software-rasterizer')
                
                driver = webdriver.Chrome(service=service, options=chrome_options)
                final_df = pd.DataFrame()

                with st.spinner('ƒêang l·∫•y ƒë√°nh gi√°...'):
                    for url in urls:
                        try:
                            df = collect_reviews_from_url(driver, url)
                            final_df = pd.concat([final_df, df], ignore_index=True)
                        except Exception as e:
                            st.error(f"L·ªói khi x·ª≠ l√Ω URL {url}: {e}")

                save_to_csv(final_df)
                driver.quit()

                st.session_state.final_df = final_df

                st.write('**B·∫£ng Comment thu th·∫≠p ƒë∆∞·ª£c:**')
                st.dataframe(st.session_state.final_df, use_container_width=True)

                with st.container():
                    st.header("Ph√¢n t√≠ch c·∫£m x√∫c")
                    with st.spinner('ƒêang ph√¢n t√≠ch c·∫£m x√∫c...'):
                        # X·ª≠ l√Ω vƒÉn b·∫£n
                        st.session_state.final_df['Processed Review Text'] = st.session_state.final_df['Review Text'].apply(preprocess_text)
                        inputs = tokenizer_sentiment(st.session_state.final_df['Processed Review Text'].tolist(), return_tensors="pt", truncation=True, padding=True)
                        outputs = model_sentiment(**inputs)
                        logits = outputs.logits
                        sentiments = torch.argmax(logits, dim=-1).numpy()
                        sentiment_labels = ['Ti√™u c·ª±c', 'Trung t√≠nh', 'T√≠ch c·ª±c']
                        st.session_state.final_df['Sentiment'] = [sentiment_labels[sentiment] for sentiment in sentiments]
                        st.write('**B·∫£ng ƒë√°nh gi√° sau khi ƒë∆∞·ª£c x·ª≠ l√Ω:**')
                        st.dataframe(st.session_state.final_df[['Review Text', 'Processed Review Text', 'Rating', 'Sentiment']], use_container_width=True)
                        st.session_state.sentiment_counts = st.session_state.final_df['Sentiment'].value_counts()

                # V·∫Ω bi·ªÉu ƒë·ªì
                with st.container():
                    st.header("Visualize")
                    st.write('**S·ªë l∆∞·ª£ng ƒë√°nh gi√° theo c·∫£m x√∫c:**')
                    with st.spinner('ƒêang v·∫Ω bi·ªÉu ƒë·ªì'):
                        if not st.session_state.final_df.empty:
                            sentiment_counts = st.session_state.sentiment_counts
                            st.session_state.fig = px.bar(sentiment_counts, 
                                                           x=sentiment_counts.index, 
                                                           y=sentiment_counts.values, 
                                                           labels={'x': 'Lo·∫°i c·∫£m x√∫c', 'y': 'S·ªë l∆∞·ª£ng'},
                                                           title="Bi·ªÉu ƒë·ªì bi·ªÉu di·ªÖn s·ªë l∆∞·ª£ng c·ªßa t·ª´ng lo·∫°i c·∫£m x√∫c")
                            st.plotly_chart(st.session_state.fig)

                            col1, col2 = st.columns(2)
                                # Word Cloud cho c·∫£m x√∫c ti√™u c·ª±c
                            with col1:
                                # st.header("Word Cloud t·ª´ c√°c ƒë√°nh gi√° Ti√™u c·ª±c")
                                st.write('**Word Cloud t·ª´ c√°c ƒë√°nh gi√° Ti√™u c·ª±c:**')
                                negative_text = ' '.join(st.session_state.final_df[st.session_state.final_df['Sentiment'] == 'Ti√™u c·ª±c']['Processed Review Text'])
                                if negative_text:  # Ki·ªÉm tra n·∫øu c√≥ b√¨nh lu·∫≠n ti√™u c·ª±c
                                    negative_wordcloud = WordCloud(width=400, height=300, background_color='white', max_words=100, colormap='viridis').generate(negative_text)
                                    plt.figure(figsize=(4, 3))
                                    plt.imshow(negative_wordcloud, interpolation='bilinear')
                                    plt.axis('off')
                                    st.pyplot(plt)
                                else:
                                    st.warning("Kh√¥ng c√≥ ƒë√°nh gi√° ti√™u c·ª±c n√†o ƒë·ªÉ v·∫Ω Word Cloud.")

                            # Word Cloud cho c·∫£m x√∫c t√≠ch c·ª±c
                            with col2:
                                # st.header("Word Cloud t·ª´ c√°c ƒë√°nh gi√° T√≠ch c·ª±c")
                                st.write('**Word Cloud t·ª´ c√°c ƒë√°nh gi√° T√≠ch c·ª±c:**')
                                positive_text = ' '.join(st.session_state.final_df[st.session_state.final_df['Sentiment'] == 'T√≠ch c·ª±c']['Processed Review Text'])
                                if positive_text:  # Ki·ªÉm tra n·∫øu c√≥ b√¨nh lu·∫≠n t√≠ch c·ª±c
                                    positive_wordcloud = WordCloud(width=400, height=300, background_color='white', max_words=100, colormap='viridis').generate(positive_text)
                                    plt.figure(figsize=(4, 3))
                                    plt.imshow(positive_wordcloud, interpolation='bilinear')
                                    plt.axis('off')
                                    st.pyplot(plt)
                                else:
                                    st.warning("Kh√¥ng c√≥ ƒë√°nh gi√° t√≠ch c·ª±c n√†o ƒë·ªÉ v·∫Ω Word Cloud.")
                                    
                            # Trung b√¨nh Rating theo nƒÉm
                            st.write("**Trung b√¨nh ƒëi·ªÉm ƒë√°nh gi√° Rating theo th·ªùi gian**")
                            final_df['Year'] = final_df['Review Time'].apply(convert_to_date)
                            final_df['Rating'] = final_df['Rating'].apply(lambda x: int(x.replace(' sao', '')))
                            avg_rating_per_year = final_df.groupby('Year')['Rating'].mean().reset_index()

                            fig_rating = px.line(avg_rating_per_year, 
                                                  x='Year', 
                                                  y='Rating', 
                                                  title='Trung b√¨nh Rating theo nƒÉm', 
                                                  labels={'Rating': 'Trung b√¨nh Rating', 'Year': 'NƒÉm'},
                                                  markers=True)
                            st.plotly_chart(fig_rating)
                        else:
                            st.warning("Vui l√≤ng tr√≠ch xu·∫•t comment tr∆∞·ªõc.") 
            else:
                st.warning("Vui l√≤ng nh·∫≠p URL h·ª£p l·ªá.")

if __name__ == "__main__":
    main()
